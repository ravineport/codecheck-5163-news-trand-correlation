### どのように実装したか
`python 3.5.1`  
朝日新聞APIの処理部分と品詞判定の部分は，それぞれクラスに分けました．  
また，品詞判定はgoo 形態素解析APIを利用しています．  
goo APIの処理は複雑な計算ではなかったので，クラスに分離はしていません．  
goo APIを叩く際，キーワード毎に叩くようにしています．これは，キーワードに区切り文字が入っていた場合を考慮してそのようにしました．


### 工夫した点
各APIを叩く箇所をすべて非同期処理にしました．  
また，あるキーワードに対する記事の数が100を超えていた場合に100ずつ取ってくる処理も非同期で処理するようにしています．  
ネットワークを介す処理はすべて非同期で，必要な結果が返ってきたら処理するように心がけてました．

goo APIのapi keyは隠しておきたい情報なので，環境変数に設定するようにしています．


### 発生した問題、難しかった箇所
Webエディタで実行したときの，エンコードのエラーではまりました．Webエディタの環境もUTF-8のように見えたので悩みました．  
`surrogateescape`というエラーハンドラで解決できました．

問題とは直接関係ないのですが，githubの最新コミットがWebエディタに反映されない問題がありました．  
問い合わせた結果，githubのwebhookのタブから状態を確認し，Redeliverすることで解決できました．ありがとうございました．
